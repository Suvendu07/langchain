{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mwd9XcMVtpTo"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_core.documents import Document"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Your source documents\n",
        "documents = [\n",
        "    Document(page_content=\"LangChain helps developers build LLM applications easily.\"),\n",
        "    Document(page_content=\"Chroma is a vector database optimized for LLM-based search.\"),\n",
        "    Document(page_content=\"Embeddings convert text into high-dimensional vectors.\"),\n",
        "    Document(page_content=\"OpenAI provides powerful embedding models.\"),\n",
        "]"
      ],
      "metadata": {
        "id": "lCCeTKkWtx5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Initialize embedding model\n",
        "embedding_model = OpenAIEmbeddings()\n",
        "\n",
        "# Step 3: Create Chroma vector store in memory\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=documents,\n",
        "    embedding=embedding_model,\n",
        "    collection_name=\"my_collection\"\n",
        ")"
      ],
      "metadata": {
        "id": "7uYjPgxFt09z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Convert vectorstore into a retriever\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})"
      ],
      "metadata": {
        "id": "tThoyCxWt3lK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is Chroma used for?\"\n",
        "results = retriever.invoke(query)"
      ],
      "metadata": {
        "id": "I5l0rXl67v4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, doc in enumerate(results):\n",
        "    print(f\"\\n--- Result {i+1} ---\")\n",
        "    print(doc.page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMAEeCxK7yRR",
        "outputId": "7f140c90-bf2d-4d54-8988-813b74ed281b",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Result 1 ---\n",
            "Chroma is a vector database optimized for LLM-based search.\n",
            "\n",
            "--- Result 2 ---\n",
            "LangChain helps developers build LLM applications easily.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = vectorstore.similarity_search(query, k=2)"
      ],
      "metadata": {
        "id": "hh0zC7L6R1Zn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, doc in enumerate(results):\n",
        "    print(f\"\\n--- Result {i+1} ---\")\n",
        "    print(doc.page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7kYMau5R1sC",
        "outputId": "d7b05617-45d7-4584-d18a-a578e4a28e89",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Result 1 ---\n",
            "Chroma is a vector database optimized for LLM-based search.\n",
            "\n",
            "--- Result 2 ---\n",
            "LangChain helps developers build LLM applications easily.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# in this retriever we retrive the similarity from the document with the help of retriever concept\n",
        "# but the same things we can do directly from chromadb vector store\n",
        "\n",
        "# so that why we use retriever"
      ],
      "metadata": {
        "id": "stTjxhRCu_Rz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}